{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingers 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = df = spark.read.csv(join('datasets', 'airlines.csv'), header=True)\n",
    "flights = df = spark.read.csv(join('datasets', 'flights.csv'), header=True)\n",
    "airports = df = spark.read.csv(join('datasets', 'airports.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.createOrReplaceTempView(\"airlines\")\n",
    "flights.createOrReplaceTempView(\"flights\")\n",
    "airports.createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora me fijo que columnas hay en los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|IATA_CODE|             AIRLINE|\n",
      "+---------+--------------------+\n",
      "|       UA|United Air Lines ...|\n",
      "|       AA|American Airlines...|\n",
      "|       US|     US Airways Inc.|\n",
      "|       F9|Frontier Airlines...|\n",
      "|       B6|     JetBlue Airways|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * from airlines LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|IATA_CODE|             AIRPORT|       CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|      ABE|Lehigh Valley Int...|  Allentown|   PA|    USA|40.65236| -75.44040|\n",
      "|      ABI|Abilene Regional ...|    Abilene|   TX|    USA|32.41132| -99.68190|\n",
      "|      ABQ|Albuquerque Inter...|Albuquerque|   NM|    USA|35.04022|-106.60919|\n",
      "|      ABR|Aberdeen Regional...|   Aberdeen|   SD|    USA|45.44906| -98.42183|\n",
      "|      ABY|Southwest Georgia...|     Albany|   GA|    USA|31.53552| -84.19447|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * from airports LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|           col_name|\n",
      "+-------------------+\n",
      "|               YEAR|\n",
      "|              MONTH|\n",
      "|                DAY|\n",
      "|        DAY_OF_WEEK|\n",
      "|            AIRLINE|\n",
      "|      FLIGHT_NUMBER|\n",
      "|        TAIL_NUMBER|\n",
      "|     ORIGIN_AIRPORT|\n",
      "|DESTINATION_AIRPORT|\n",
      "|SCHEDULED_DEPARTURE|\n",
      "|     DEPARTURE_TIME|\n",
      "|    DEPARTURE_DELAY|\n",
      "|           TAXI_OUT|\n",
      "|         WHEELS_OFF|\n",
      "|     SCHEDULED_TIME|\n",
      "|       ELAPSED_TIME|\n",
      "|           AIR_TIME|\n",
      "|           DISTANCE|\n",
      "|          WHEELS_ON|\n",
      "|            TAXI_IN|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SHOW COLUMNS from flights').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aeropuertos con mayor cantidad de cancelaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a mostrar los 5 aeropuertos de origen que tienen mayor cantidad de cancelaciones. Como el enunciado no lo aclara mostraremos tanto el código iata como el nombre del aeropuerto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------------+\n",
      "|IATA_CODE|             AIRPORT|total_cancelled|\n",
      "+---------+--------------------+---------------+\n",
      "|      ORD|Chicago O'Hare In...|           8548|\n",
      "|      DFW|Dallas/Fort Worth...|           6254|\n",
      "|      LGA|LaGuardia Airport...|           4531|\n",
      "|      EWR|Newark Liberty In...|           3110|\n",
      "|      BOS|Gen. Edward Lawre...|           2654|\n",
      "+---------+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT first(flights.ORIGIN_AIRPORT) as IATA_CODE, airports.AIRPORT, COUNT(*) as total_cancelled\\\n",
    "    FROM flights INNER JOIN airports\\\n",
    "    ON flights.ORIGIN_AIRPORT = airports.IATA_CODE\\\n",
    "    WHERE CANCELLED = 1\\\n",
    "    GROUP BY airports.AIRPORT\\\n",
    "    ORDER BY total_cancelled DESC\\\n",
    "    LIMIT 5\\\n",
    "').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aeropuertos con mayor cantidad de cancelaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora mostraremos el nombre de aerolíneas y la cantidad de vuelos desde Atlanta (ATL) a Los Ángeles (LAX) ordenados por cantidad de vuelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             AIRLINE|cantidad_de_vuelos|\n",
      "+--------------------+------------------+\n",
      "|Delta Air Lines Inc.|              3624|\n",
      "|Southwest Airline...|               962|\n",
      "|American Airlines...|               765|\n",
      "|Frontier Airlines...|               215|\n",
      "|    Spirit Air Lines|               103|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = spark.sql('SELECT airlines.AIRLINE, count(*) as cantidad_de_vuelos FROM flights\\\n",
    "    INNER JOIN airlines ON \\\n",
    "    flights.AIRLINE = airlines.IATA_CODE \\\n",
    "    WHERE flights.ORIGIN_AIRPORT = \"ATL\" AND flights.DESTINATION_AIRPORT = \"LAX\" \\\n",
    "    GROUP BY airlines.AIRLINE \\\n",
    "    ORDER BY cantidad_de_vuelos DESC \\\n",
    "')\n",
    "\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de query\n",
    "Analizaremos la query ejecutada en el punto anterior. Para ello primero mostramos las optimizaciones realizadas por Catalyst Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['cantidad_de_vuelos DESC NULLS LAST], true\n",
      "+- 'Aggregate ['airlines.AIRLINE], ['airlines.AIRLINE, 'count(1) AS cantidad_de_vuelos#194]\n",
      "   +- 'Filter (('flights.ORIGIN_AIRPORT = ATL) && ('flights.DESTINATION_AIRPORT = LAX))\n",
      "      +- 'Join Inner, ('flights.AIRLINE = 'airlines.IATA_CODE)\n",
      "         :- 'UnresolvedRelation `flights`\n",
      "         +- 'UnresolvedRelation `airlines`\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "AIRLINE: string, cantidad_de_vuelos: bigint\n",
      "Sort [cantidad_de_vuelos#194L DESC NULLS LAST], true\n",
      "+- Aggregate [AIRLINE#11], [AIRLINE#11, count(1) AS cantidad_de_vuelos#194L]\n",
      "   +- Filter ((ORIGIN_AIRPORT#31 = ATL) && (DESTINATION_AIRPORT#32 = LAX))\n",
      "      +- Join Inner, (AIRLINE#28 = IATA_CODE#10)\n",
      "         :- SubqueryAlias flights\n",
      "         :  +- Relation[YEAR#24,MONTH#25,DAY#26,DAY_OF_WEEK#27,AIRLINE#28,FLIGHT_NUMBER#29,TAIL_NUMBER#30,ORIGIN_AIRPORT#31,DESTINATION_AIRPORT#32,SCHEDULED_DEPARTURE#33,DEPARTURE_TIME#34,DEPARTURE_DELAY#35,TAXI_OUT#36,WHEELS_OFF#37,SCHEDULED_TIME#38,ELAPSED_TIME#39,AIR_TIME#40,DISTANCE#41,WHEELS_ON#42,TAXI_IN#43,SCHEDULED_ARRIVAL#44,ARRIVAL_TIME#45,ARRIVAL_DELAY#46,DIVERTED#47,... 7 more fields] csv\n",
      "         +- SubqueryAlias airlines\n",
      "            +- Relation[IATA_CODE#10,AIRLINE#11] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [cantidad_de_vuelos#194L DESC NULLS LAST], true\n",
      "+- Aggregate [AIRLINE#11], [AIRLINE#11, count(1) AS cantidad_de_vuelos#194L]\n",
      "   +- Project [AIRLINE#11]\n",
      "      +- Join Inner, (AIRLINE#28 = IATA_CODE#10)\n",
      "         :- Project [AIRLINE#28]\n",
      "         :  +- Filter ((((isnotnull(ORIGIN_AIRPORT#31) && isnotnull(DESTINATION_AIRPORT#32)) && (ORIGIN_AIRPORT#31 = ATL)) && (DESTINATION_AIRPORT#32 = LAX)) && isnotnull(AIRLINE#28))\n",
      "         :     +- Relation[YEAR#24,MONTH#25,DAY#26,DAY_OF_WEEK#27,AIRLINE#28,FLIGHT_NUMBER#29,TAIL_NUMBER#30,ORIGIN_AIRPORT#31,DESTINATION_AIRPORT#32,SCHEDULED_DEPARTURE#33,DEPARTURE_TIME#34,DEPARTURE_DELAY#35,TAXI_OUT#36,WHEELS_OFF#37,SCHEDULED_TIME#38,ELAPSED_TIME#39,AIR_TIME#40,DISTANCE#41,WHEELS_ON#42,TAXI_IN#43,SCHEDULED_ARRIVAL#44,ARRIVAL_TIME#45,ARRIVAL_DELAY#46,DIVERTED#47,... 7 more fields] csv\n",
      "         +- Filter isnotnull(IATA_CODE#10)\n",
      "            +- Relation[IATA_CODE#10,AIRLINE#11] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(4) Sort [cantidad_de_vuelos#194L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(cantidad_de_vuelos#194L DESC NULLS LAST, 200)\n",
      "   +- *(3) HashAggregate(keys=[AIRLINE#11], functions=[count(1)], output=[AIRLINE#11, cantidad_de_vuelos#194L])\n",
      "      +- Exchange hashpartitioning(AIRLINE#11, 200)\n",
      "         +- *(2) HashAggregate(keys=[AIRLINE#11], functions=[partial_count(1)], output=[AIRLINE#11, count#207L])\n",
      "            +- *(2) Project [AIRLINE#11]\n",
      "               +- *(2) BroadcastHashJoin [AIRLINE#28], [IATA_CODE#10], Inner, BuildRight\n",
      "                  :- *(2) Project [AIRLINE#28]\n",
      "                  :  +- *(2) Filter ((((isnotnull(ORIGIN_AIRPORT#31) && isnotnull(DESTINATION_AIRPORT#32)) && (ORIGIN_AIRPORT#31 = ATL)) && (DESTINATION_AIRPORT#32 = LAX)) && isnotnull(AIRLINE#28))\n",
      "                  :     +- *(2) FileScan csv [AIRLINE#28,ORIGIN_AIRPORT#31,DESTINATION_AIRPORT#32] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/D:/UBA/Datos/notebooks/fingers/datasets/flights.csv], PartitionFilters: [], PushedFilters: [IsNotNull(ORIGIN_AIRPORT), IsNotNull(DESTINATION_AIRPORT), EqualTo(ORIGIN_AIRPORT,ATL), EqualTo(..., ReadSchema: struct<AIRLINE:string,ORIGIN_AIRPORT:string,DESTINATION_AIRPORT:string>\n",
      "                  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n",
      "                     +- *(1) Project [IATA_CODE#10, AIRLINE#11]\n",
      "                        +- *(1) Filter isnotnull(IATA_CODE#10)\n",
      "                           +- *(1) FileScan csv [IATA_CODE#10,AIRLINE#11] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/D:/UBA/Datos/notebooks/fingers/datasets/airlines.csv], PartitionFilters: [], PushedFilters: [IsNotNull(IATA_CODE)], ReadSchema: struct<IATA_CODE:string,AIRLINE:string>\n"
     ]
    }
   ],
   "source": [
    "query.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Se realiza alguna optimización lógica, como filter pushdown? ¿En qué etapa?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un filter pushdown en la etapa de Pysical Plan. Esto se ve dado que en la etapa anterior el filter se realizaba después del join, y luego se termina realizando antes del join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Que tipo de Join Físico se realiza? ¿En qué etapa?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que en las etapas anteriores al Phisical Plan se utilizaría un inner join, sin embargo en esta última etapa vemos que termina utilizando un BroadcastHashJoin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
